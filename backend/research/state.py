"""
Core state definitions for the Deep Research Application.
Defines the shared data structures used by the Orchestrator, Workers, and Activities.
"""

import os
import uuid
from typing import Any, Literal

from pydantic import BaseModel, Field

try:
    from temporalio import workflow
except ImportError:
    workflow = None  # type: ignore


def safe_uuid4() -> str:
    """Returns a UUID4 string, using Temporal's deterministic generator if in a workflow."""
    if workflow:
        try:
            return str(workflow.uuid4())
        except Exception:
            # Not in a workflow context or Temporal event loop
            pass
    return str(uuid.uuid4())


def safe_getenv(key: str, default: Any = None) -> Any:
    """Return the environment variable using os.getenv; does not perform Temporal sandbox handling."""
    return os.getenv(key, default)


# --- Core Type Definitions ---

VerificationStatus = Literal["VERIFIED", "UNVERIFIED", "UNCERTAIN", "REJECTED"]


# --- Core Entity Definitions ---


class EvidenceSnippet(BaseModel):
    """Stores verbatim text evidence with its source and timestamp."""

    source_url: str
    content: str
    timestamp: str  # ISO format


class Entity(BaseModel):
    """Represents a discovered entity with its metadata and evidence."""

    canonical_name: str
    # Raw strings found in text (e.g. "BMS-986158", "Compound 7")
    aliases: set[str] = Field(default_factory=set)
    # Structured data
    drug_class: str | None = None
    clinical_phase: str | None = None
    # Flexible attributes
    attributes: dict[str, str] = Field(default_factory=dict)
    # Verbatim excerpts backing the entity
    evidence: list[EvidenceSnippet] = Field(default_factory=list)
    # Count of times extracted
    mention_count: int = 0

    # Verification Status
    verification_status: VerificationStatus = "UNVERIFIED"
    rejection_reason: str | None = None
    confidence_score: float = 0.0


# --- Worker State & Metrics ---


class SearchParameters(BaseModel):
    """Dynamic search parameters generated by LLM for each query."""

    # Common parameters
    max_results: int | None = None
    country: str | None = None  # ISO country code or full name

    # Perplexity-specific
    perplexity_domain_filter: list[str] | None = None
    perplexity_language_filter: list[str] | None = None

    # Tavily-specific
    tavily_search_depth: str | None = None  # basic | fast | advanced | ultra-fast
    tavily_topic: str | None = None  # general | news | finance
    tavily_time_range: str | None = None  # day | week | month | year
    tavily_include_domains: list[str] | None = None
    tavily_exclude_domains: list[str] | None = None

    # Reasoning
    reasoning: str | None = None


class WorkerState(BaseModel):
    """State of each parallel worker agent."""

    id: str = Field(default_factory=safe_uuid4)
    research_id: str
    strategy: str  # High-level strategy name
    queries: list[str | dict] = Field(
        default_factory=list
    )  # List of query strings or dicts with parameters
    page_budget: int = Field(
        default_factory=lambda: int(safe_getenv("WORKER_PAGE_BUDGET", "50"))
    )
    status: str = "ACTIVE"

    # Metrics
    pages_fetched: int = 0
    entities_found: int = 0
    new_entities: int = 0

    # Link Discovery
    personal_queue: list[str] = Field(default_factory=list)

    # Query execution tracking
    query_history: list[dict] = Field(
        default_factory=list, description="History of queries executed by this worker"
    )
    # Each entry: {"query": str, "iteration": int, "results_count": int, "new_entities": int}

    # NEW: Performance tracking per query
    query_performance: dict[str, dict] = Field(default_factory=dict)
    # Format: {"query_text": {"total_pages": 20, "new_entities": 5, "novelty_rate": 0.25}}

    # NEW: Domain diversity tracking
    explored_domains: set[str] = Field(default_factory=set)

    # NEW: Search engine tracking
    search_engine_history: list[dict] = Field(default_factory=list)
    # Format: [{"query": "...", "engine": "perplexity", "results": 10, "new_entities": 3}]

    # PHASE 3: Link yield tracking for adaptive learning
    link_performance: dict[str, dict] = Field(default_factory=dict)
    # Format: {"domain": {"links_added": 50, "entities_found": 12, "yield_rate": 0.24}}


# --- Strategic Planning ---


class Gap(BaseModel):
    """Represents a missing piece of information or coverage gap."""

    description: str
    priority: Literal["low", "medium", "high"]
    reasoning: str


class InitialWorkerStrategy(BaseModel):
    worker_id: str = Field(default_factory=safe_uuid4)
    strategy: str
    strategy_description: str
    example_queries: list[str]
    page_budget: int = Field(
        default_factory=lambda: int(safe_getenv("WORKER_PAGE_BUDGET", "50"))
    )
    status: Literal["ACTIVE"] = "ACTIVE"


class ResearchPlan(BaseModel):
    """Encapsulates the current strategic understanding and next steps."""

    # New fields for Expert Planning
    query_analysis: dict[str, Any] = Field(
        default_factory=dict, description="Structured analysis of the user query"
    )
    synonyms: dict[str, list[str]] = Field(
        default_factory=dict, description="Generated synonyms for targets/indications"
    )
    initial_workers: list[InitialWorkerStrategy] = Field(
        default_factory=list, description="Initial spawn configuration"
    )
    budget_reserve_pct: float = Field(
        default_factory=lambda: float(safe_getenv("BUDGET_RESERVE_PCT", "0.6")),
        description="Percentage of budget to reserve for adaptive phase",
    )
    reasoning: str = Field(
        default="", description="Explanation of the planning strategy"
    )
    cost: float = Field(default=0.0, description="Cost of the planning phase")

    # Legacy/Computed fields used by Orchestrator
    current_hypothesis: str = "Plan Generated"
    findings_summary: str = "Initial Planning Complete"
    gaps: list[Gap] = Field(default_factory=list)
    next_steps: list[str] = Field(default_factory=list)

    # Adaptive planning outputs
    workers_to_kill: list[str] = Field(
        default_factory=list, description="Worker IDs to kill this iteration"
    )
    updated_queries: dict[str, list[str]] = Field(
        default_factory=dict,
        description="New queries for existing workers {worker_id: [queries]}",
    )


# --- Global Orchestrator State ---


class ResearchState(BaseModel):
    """Manages the global state of the research process, including entities and workers."""

    id: str = Field(default_factory=safe_uuid4)

    topic: str
    status: Literal[
        "initialized", "running", "verification_pending", "completed", "failed"
    ] = "initialized"
    total_cost: float = Field(
        default=0.0, description="Total cost of the research session"
    )

    # Global Knowledge Base
    # Key: Normalized entity string
    known_entities: dict[str, Entity] = Field(default_factory=dict)

    # Global Concurrency Control
    visited_urls: set[str] = Field(default_factory=set)

    # Worker Management
    workers: dict[str, WorkerState] = Field(default_factory=dict)

    # Strategic Plan (The "Brain")
    plan: ResearchPlan = Field(
        default_factory=lambda: ResearchPlan(
            current_hypothesis="Initial state",
            findings_summary="None",
            gaps=[],
            next_steps=["Initial Analysis"],
        )
    )

    iteration_count: int = 0
    consecutive_low_novelty_count: int = 0
    logs: list[str] = Field(default_factory=list)

    # Discovery tracking for gap detection
    discovered_code_names: set[str] = Field(
        default_factory=set, description="Code names found in entity aliases"
    )
    discovered_companies: set[str] = Field(
        default_factory=set, description="Company names mentioned in entity context"
    )
    high_value_urls: list[str] = Field(
        default_factory=list, description="URLs discovered but not yet explored"
    )
